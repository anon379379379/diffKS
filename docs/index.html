<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Differentiable Karplus-Strong Synthesis for Neural Resonance Optimisation</title>

  <!-- ======== SOCIAL / SEO ======== -->
  <meta name="description"  content="Differentiable Karplus-Strong Synthesis for Neural Resonance Optimisation â€“ project page with audio examples" />
  <meta property="og:title"        content="Differentiable Karplus-Strong Synthesis for Neural Resonance Optimisation" />
  <meta property="og:description"  content="Audio examples and paper for DiffKS â€“ a differentiable Karplus-Strong string-synthesis model" />
  <meta property="og:url"          content="URL OF THE WEBSITE" />
  <meta property="og:image"        content="static/image/your_banner_image.png" />
  <meta property="og:image:width"  content="1200" />
  <meta property="og:image:height" content="630" />
  <meta name="twitter:title"  content="DiffKS â€“ Differentiable Karplus-Strong Synthesis" />
  <meta name="twitter:image"  content="static/images/your_twitter_banner_image.png" />
  <meta name="twitter:card"   content="summary_large_image" />
  <meta name="keywords"       content="audio synthesis, differentiable DSP, Karplus-Strong, gradient descent, autoencoder, WASPAA 2025" />

  <!-- fonts & icons (explicitly load 700 & 800 weights to guarantee bold) -->
  <link href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;700;800&family=Noto+Sans:wght@400;700;800&family=Castoro&display=swap" rel="stylesheet" />
  <link href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" rel="stylesheet" />
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" rel="stylesheet" />

  <!-- ======== STYLES ======== -->
  <style>
    body{font-family:'Google Sans','Noto Sans',Arial,sans-serif;line-height:1.6;color:#333;max-width:1200px;margin:0 auto;padding:20px}
    .container{max-width:900px;margin:0 auto;padding:0 20px}
    h1,h2,h3{text-align:center;margin-bottom:1.5rem}
    h1{color:#2c3e50;margin-bottom:2rem}
    h2{color:#34495e;margin-top:3rem;margin-bottom:2rem}
    .abstract{background:#f8f9fa;padding:2rem;border-radius:8px;margin:2rem 0;text-align:justify}

    table{border-collapse:collapse;width:100%;max-width:900px;margin:2rem auto;box-shadow:0 2px 8px rgba(0,0,0,.1);border-radius:8px;overflow:hidden}
    th,td{border:1px solid #e1e5e9;padding:10px;text-align:center}
    th{background:#f0f0f0;font-weight:600}

    .play-btn,.ctrl-btn{cursor:pointer;padding:6px 14px;background:#007BFF;color:#fff;border:none;border-radius:6px;font-size:15px;transition:.3s;box-shadow:0 2px 4px rgba(0,0,0,.1)}
    .play-btn:hover,.ctrl-btn:hover{transform:translateY(-1px);box-shadow:0 4px 8px rgba(0,0,0,.15)}
    .waveform,.spectrogram{height:80px;background:#e8e8e8;margin:6px 0;border-radius:4px;border:1px solid #ddd}
    .controls{display:flex;justify-content:center;gap:6px;margin-bottom:10px}

    .playerHead{text-align:center;margin-top:3rem}
    .hero{margin:2rem 0}

    .button{display:inline-block;padding:10px 18px;text-decoration:none;border-radius:6px;transition:.3s}
    .is-dark{background:#2c3e50;color:#fff}
    .is-dark:hover{background:#34495e;transform:translateY(-1px)}

    /* metrics table */
    .metrics th,.metrics td{font-size:14px}
    .metrics td strong,
    .metrics th strong,
    .metrics td span[style*="font-weight:700"]{font-weight:800 !important;}
  </style>
</head>
<body>
  <!-- ===== HEADER ===== -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered"><div class="column has-text-centered">
          <h1 class="title is-1">Differentiable Karplus-Strong Synthesis for Neural Resonance Optimisation</h1>
          <div class="is-size-5"><span>Anonymous Authors</span><br><span>Submitted to WASPAA 2025</span></div>
          <div style="margin-top:1rem"><a href="static/paper.pdf" target="_blank" class="button is-dark is-rounded"><i class="fas fa-file-pdf"></i>&nbsp;Paper</a></div>
        </div></div>
      </div>
    </div>
  </section>

  <!-- ===== ABSTRACT & FIGURE ===== -->
  <section class="section hero is-light"><div class="container is-max-desktop">
    <h2 class="title is-3">Abstract</h2>
    <div class="abstract"><p>The Karplus-Strong algorithm is a well-known approach for realistic string simulation through a highly efficient formulation, but parameter optimisation traditionally relies on manual tuning or non-differentiable optimisation methods. We present DiffKS, a fully differentiable time-domain implementation of Karplus-Strong synthesis that enables resonance optimisation through gradient descent. Our time-domain formulation allows for expressive pitch and timbre modulation while learning exact gradients. Inspired by commuted synthesis, we propose a two-filtering stage pipeline: an excitation filter capturing pluck absorption, and a loop filter modelling the system's body resonance. A preceding inverse-filtering stage uses the learnt impulse response to extract plucking information. We demonstrate that DiffKS can optimise by gradient descent and outperforms genetic algorithm optimisation perceptually and in terms of computational efficiency. Additionally, we embed DiffKS onto an autoencoder neural network and compare it to a previous neural supervised approach. We find our proposed architecture converges substantially quicker than its supervised counterpart and learns a latent representation that accurately captures the resonance of an acoustic guitar.</p></div>

    <img src="images/diffKS_diagram.svg" alt="DiffKS diagram" style="width:100%;border-radius:8px;box-shadow:0 2px 8px rgba(0,0,0,.1)">
    <p style="text-align:center;font-size:0.9rem;margin-top:0.4rem"><strong>Figure 1: Diagram of our proposed DiffKS architecture.</strong></p>
    <p style="text-align:center;font-size:0.9rem">The learnable parameters are shown in a pink â†’ egg-white gradient. On the right, a forward custom Extended Karplus-Strong (EKS) generates the resonant output; on the left, its inversion extracts the pluck excitation. Note that the learnable parameters are tied between both branches; i.e. The trainable vector Î¸ is used once for the forward EKS and again for the inversed EKS. For clarity, inversion collapses excitation filter coefficients <code>a<sub>3</sub></code>, <code>a<sub>2</sub></code>, and <code>a<sub>1</sub></code>, while forward mode collapses <code>a<sub>2</sub></code>, <code>a<sub>3</sub></code>, and <code>a<sub>4</sub></code>. Blocks with points joint by dashed-lines and a tuning-fork icon denote linear interpolation and tuning operations. *Since our proposed EKS and inversed EKS are exact mirroring operations, we zero the recovered excitation data outside of a 25ms window. Not doing this would result in a no-op.</p>
  </div></section>

  <!-- ===== AUDIO TABLE CONTAINERS ===== -->
  <section class="hero is-small"><div class="hero-body"><div class="container" id="container-flow"></div></div></section>
  <section class="hero is-small"><div class="hero-body"><div class="container" id="container-grad_vs_gen"></div></div></section>
  <section class="hero is-small is-light"><div class="hero-body"><div class="container" id="container-ae"></div></div></section>

  <!-- ===== BIBTEX ===== -->
  <section class="section" id="BibTeX"><div class="container is-max-desktop content"><h2 class="title">BibTeX</h2><pre><code>@inproceedings{diffks2025anonymous,
  title   = {Differentiable Karplus-Strong Synthesis for Neural Resonance Optimisation},
  author  = {Anonymous},
  booktitle = {Proc. IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},
  year    = {2025},
  address = {Lake Tahoe, CA}
}</code></pre></div></section>

  <!-- ===== FOOTER ===== -->
  <footer class="footer"><div class="container"><p style="text-align:center;font-size:0.85rem">Â© 2025 DiffKS â€” built from the Academic Project Page template.</p></div></footer>

  <!-- ===== PLAYER & TABLE SCRIPT ===== -->
  <script type="module">
  import WaveSurfer from 'https://cdn.jsdelivr.net/npm/wavesurfer.js@7/dist/wavesurfer.esm.js';
  import Spectrogram from 'https://cdn.jsdelivr.net/npm/wavesurfer.js@7/dist/plugins/spectrogram.js';

  /* ---------- BASIC CONFIG ---------- */
  const AUDIO_EXT='.mp4', ROWS=3;

  /* ---------- TABLE DEFINITIONS ---------- */
  const TABLES=[{
  title : 'DiffKS Path Flow',
  path  : 'flow',
  models: ['truth','inv','pred'],
  labels: { truth:'Ground Truth', inv:'Excitation', pred:'Predicted' }
},
    {
    title:'DiffKS (Gradient Descent) vs Genetic Algorithm (GA)',
    path:'grad_vs_gen',
    models:['truth','diffks','ga'],
    labels:{truth:'Ground Truth',diffks:'DiffKS',ga:'GA'},
          metrics : `
        <table class="tg metrics"><thead><tr>
          <th>Optimization Method</th><th>MSL</th><th>Param&nbsp;Loss</th>
          <th>PANNs</th><th>VGGish</th><th>CDPAM</th><th>CLAP</th>
          <th>Avg&nbsp;Iter</th><th>Total&nbsp;Time</th></tr></thead><tbody>
          <tr>
            <td>Gradient Descent</td><td><strong>0.95 Â± 0.94</strong></td><td><strong>0.21 Â± 0.07</strong></td>
            <td><strong>3.941</strong></td><td><strong>0.757</strong></td><td><strong>0.179</strong></td><td><strong>1.335</strong></td>
            <td><strong>1.24&nbsp;s</strong></td><td><strong>2&nbsp;h 4&nbsp;m 5&nbsp;s</strong></td>
          </tr>
          <tr>
            <td>Genetic Algorithm</td><td>1.18 Â± 0.80</td><td>0.23 Â± 0.02</td>
            <td>8.553</td><td>1.645</td><td>1.252</td><td>2.179</td>
            <td>13.23&nbsp;s</td><td>23&nbsp;h 3&nbsp;m 59&nbsp;s</td>
          </tr>
        </tbody></table>
         <p class="table-caption">
        <strong>Table 1:</strong> Mean Â± std. of MSL, Parameter Loss, KAD scores and wall-clock times for optimization baselines (N=100).
      </p>`
    },
    {
    title:'Auto-encoder baselines',
    path:'ae',
    models:['truth','nsynth','fcnf0pp','sup'],
    labels:{truth:'Ground Truth',nsynth:'NSynth-F0',fcnf0pp:'FCNF0++',sup:'Supervised'},
          metrics : `
        <table class="tg metrics"><thead><tr>
          <th>Autoencoder</th><th>MSL</th><th>Parameter Loss</th>
          <th>PANNs</th><th>VGGish</th><th>CDPAM</th><th>CLAP</th>
        </tr></thead><tbody>
          <tr>
            <td>Nsynth-F0</td><td><strong>0.93 Â± 0.19</strong></td><td>0.46 Â± 0.02</td>
            <td><strong>3.139</strong></td><td><strong>0.611</strong></td><td><strong>0.463</strong></td><td><strong>2.582</strong></td>
          </tr>
          <tr>
            <td>FCNF0++</td><td>1.16 Â± 0.26</td><td>0.46 Â± 0.02</td>
            <td>4.750</td><td>0.696</td><td>0.706</td><td>3.279</td>
          </tr>
          <tr>
            <td>Supervised</td><td>2.74 Â± 0.46</td><td><strong>0.13 Â± 0.01</strong></td>
            <td>31.655</td><td>9.091</td><td>15.557</td><td>7.184</td>
          </tr>
        </tbody></table>
 <p class="table-caption">
        <strong>Table 2:</strong> Mean Â± std. dev. of MSL, Parameter Loss and KAD scores for our auto-encoder baselines (N = 195).
      </p>`  }];

  /* ---------- HELPERS ---------- */
  async function getIDs(path){
    try{
      const r=await fetch(`${path}/index.json`,{cache:'no-store'});
      return r.ok?(await r.json()).samples:[];
    }catch{ return []; }
  }
  const rand=(arr,n)=>arr.slice().sort(()=>0.5-Math.random()).slice(0,Math.min(n,arr.length));
  const icon=(btn,on)=>{ btn.innerHTML = on ? '<i class="fas fa-pause"></i>' : '<i class="fas fa-play"></i>'; };

  async function filterValid (tbl, ids) {
  const checks = ids.map(async id => {
    for (const m of tbl.models) {
      const resp = await fetch(`${tbl.path}/${id}-${m}${AUDIO_EXT}`, {method:'HEAD'});
      if (!resp.ok) return null;                 // missing â†’ reject this id
    }
    return id;                                   // all files exist
  });
  return (await Promise.all(checks)).filter(Boolean);
}

  /* ---------- PLAYER CACHE ---------- */
  const players=new Map();
  function makePlayer(td,url){
    const wf = td.querySelector('.waveform');
    const sp = td.querySelector('.spectrogram');
    const ws = WaveSurfer.create({
      container:wf, backend:'MediaElement', height:80,
      waveColor:'#999', progressColor:'#007BFF',
      plugins:[ Spectrogram.create({container:sp,scale:'mel',labels:false,height:80}) ]
    });
    ws.load(url);
    return ws;
  }

  /* ---------- TABLE FACTORY ---------- */
  function shell(tbl){
    const wrap=document.getElementById(`container-${tbl.path}`);
    wrap.innerHTML='';
    wrap.insertAdjacentHTML('beforeend',`
      <div class="playerHead">
        <h2 class="title is-4">${tbl.title}</h2>
        ${tbl.metrics || ''}
        <button class="button is-small is-dark" id="shuffle-${tbl.path}">ðŸ”€ Shuffle Examples</button>
      </div>
      <table id="table-${tbl.path}">
        <thead><tr>${tbl.models.map(m=>`<th>${tbl.labels[m]}</th>`).join('')}</tr></thead>
        <tbody></tbody>
      </table>`);
    return wrap.querySelector(`#shuffle-${tbl.path}`);
  }

  function renderRows(tbl,ids){
    const tbody=document.querySelector(`#table-${tbl.path} tbody`);
    tbody.innerHTML='';

    /* destroy old players for this table */
    [...players.entries()].forEach(([btn,ws])=>{
      if(btn.dataset.path===tbl.path){ ws.destroy(); players.delete(btn); }
    });

    ids.forEach(id=>{
      const row=document.createElement('tr');
      row.dataset.sample=id;

      tbl.models.forEach(m=>{
        const td=document.createElement('td');
        td.innerHTML=`<div class="controls">
            <button class="play-btn"><i class="fas fa-play"></i></button>
            <button class="ctrl-btn" data-act="stop"><i class="fas fa-stop"></i></button>
            <button class="ctrl-btn" data-act="rew"><i class="fas fa-backward"></i></button>
          </div>
          <div class="waveform"></div>
          <div class="spectrogram"></div>`;

        const url=`${tbl.path}/${id}-${m}${AUDIO_EXT}`;
        const ws=makePlayer(td,url);
        const playB=td.querySelector('.play-btn');
        const stopB=td.querySelector('[data-act="stop"]');
        const rewB =td.querySelector('[data-act="rew"]');

        playB.onclick=()=>{
          players.forEach((other,b)=>{
            if(other.isPlaying()){ other.pause(); icon(b,false); }
          });
          if(ws.isPlaying()){ ws.pause(); icon(playB,false); }
          else              { ws.play();  icon(playB,true);  }
        };
        stopB.onclick=()=>{ ws.pause(); ws.seekTo(0); icon(playB,false); };
        rewB .onclick=()=>{ ws.seekTo(0); ws.play();  icon(playB,true);  };

        playB.dataset.path=tbl.path;
        players.set(playB,ws);
        row.appendChild(td);
      });

      tbody.appendChild(row);
    });
  }

  /* ---------- PAGE INITIALISATION ---------- */
  (async ()=>{
    for (const tbl of TABLES) {
      const shuffleBtn = shell(tbl);

      /* 1ï¸âƒ£  get the full list, but keep only fully-present samples  */
      let pool = await filterValid(tbl, await getIDs(tbl.path));

      /* 2ï¸âƒ£  choose random subset to render                        */
      let visible = rand(pool, ROWS);
      renderRows(tbl, visible);

      shuffleBtn.onclick = ()=>{ visible = rand(pool, ROWS); renderRows(tbl, visible); };
    }
  })();
  </script>
</body>
</html>
